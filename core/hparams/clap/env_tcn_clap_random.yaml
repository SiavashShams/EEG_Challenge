seed: 1234
__set_seed: !apply:torch.manual_seed [!ref <seed>]
np_rng: !new:numpy.random.RandomState [!ref <seed>]

project: EEGCh24
experiment: env_tcn_clap
save_root: ./save/clap
time_stamp: !PLACEHOLDER
save_folder: !ref <save_root>/<experiment>/<seed>

## Data and feature hparams

wav_sr: 16000
eeg_sr: 64
wav_ch: 1
eeg_ch: 64

n_mismatch: 4
win_sec: 5
hop_sec: 1

feature: envelope # the tag in file path before .npy
feature_ch: 1
feature_sr: 64

clap_batch_size: 16

## Loaders

data_root: /engram/naplab/shared/eeg_challenge_data_new/derivatives/split_data_16khz

train_windows: !new:data.dataset.RandomWindowDataset
    data_root: !ref <data_root>
    split: train
    speech_features: !ref <feature>
    eeg_sr: !ref <eeg_sr>
    feature_sr: !ref <feature_sr>
    n_win: !ref <clap_batch_size>
    win_sec: !ref <win_sec>
    rand_win: true

valid_windows: !new:data.dataset.RandomWindowDataset
    data_root: !ref <data_root>
    split: valid
    speech_features: !ref <feature>
    eeg_sr: !ref <eeg_sr>
    feature_sr: !ref <feature_sr>
    n_win: !ref <n_mismatch> + 1
    win_sec: !ref <win_sec>
    rand_win: false

train_loader_opts:
    batch_size: 1
    drop_last: true
    shuffle: true
    num_workers: 8

valid_loader_opts:
    batch_size: 1
    drop_last: false
    shuffle: false
    num_workers: 1

## Model

n_tconv: 3
kernel_size: 3
spatial_filters: 8
dilation_filters: 16
activation: !new:torch.nn.ReLU

eeg_model: !new:modules.baseline.TCN
    input_dim: !ref <eeg_ch>
    layers: !ref <n_tconv>
    kernel_size: !ref <kernel_size>
    # input dim of TCN, output dim of input_proj
    spatial_filters: !ref <spatial_filters>
    dilation_filters: !ref <dilation_filters>
    activation: !ref <activation>
    input_proj: !new:torch.nn.Conv1d
        in_channels: !ref <eeg_ch>
        out_channels: !ref <spatial_filters>
        kernel_size: 1

speech_model: !new:modules.baseline.TCN
    input_dim: !ref <feature_ch>
    layers: !ref <n_tconv>
    kernel_size: !ref <kernel_size>
    # input dim of TCN, output dim of input_proj
    spatial_filters: !ref <feature_ch>
    dilation_filters: !ref <dilation_filters>
    activation: !ref <activation>
    input_proj: !new:torch.nn.Identity

clap_ch: 4
tau: 0.07

clap: !new:modules.clap.CLAP
    speech_model: !ref <speech_model>
    eeg_model: !ref <eeg_model>
    d_speech: !ref <dilation_filters>
    d_eeg: !ref <dilation_filters>
    d_proj: !ref <clap_ch>
    tau: !ref <tau>

compute_cross_sim_cost: !new:torch.nn.CrossEntropyLoss

# Put every nn.Module here
modules:
    clap: !ref <clap>

## Training

loss_fn: !name:torch.nn.functional.cross_entropy

n_epoch: 1000
lr: 1.0e-3
patience: 50

mix_prec: false
mix_dtype: !name:torch.bfloat16 # always

optimizer: !name:torch.optim.Adam
    lr: !ref <lr>

lr_scheduler: !name:torch.optim.lr_scheduler.ReduceLROnPlateau
    mode: 'min'
    factor: 0.5
    patience: !ref <patience>
    verbose: true

epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
    limit: !ref <n_epoch>

checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
    checkpoints_dir: !ref <save_folder>
    recoverables:
        clap: !ref <clap>
        epoch_counter: !ref <epoch_counter>

## Logging

me: xj-audio
use_wandb: false
resume: false
wandb_logger: !name:speechbrain.utils.train_logger.WandBLogger
    initializer: !name:wandb.init
    entity: !ref <me>
    project: !ref <project>
    name: !ref <experiment>-<time_stamp>
    dir: !ref <save_folder>
    resume: !ref <resume>
