{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T03:09:23.203923600Z",
     "start_time": "2023-11-22T03:09:13.995945500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 22:09:15.484934: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-21 22:09:15.484997: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-21 22:09:15.486223: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-21 22:09:15.495321: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-21 22:09:18.098030: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\"\"\"2 mismatched segments dilation model.\"\"\"\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def dilation_model(\n",
    "    time_window=None,\n",
    "    eeg_input_dimension=64,\n",
    "    env_input_dimension=1,\n",
    "    layers=3,\n",
    "    kernel_size=3,\n",
    "    spatial_filters=8,\n",
    "    dilation_filters=16,\n",
    "    activation=\"relu\",\n",
    "    compile=True,\n",
    "    num_mismatched_segments=2\n",
    "):\n",
    "    \"\"\"Convolutional dilation model.\n",
    "\n",
    "    Code was taken and adapted from\n",
    "    https://github.com/exporl/eeg-matching-eusipco2020\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time_window : int or None\n",
    "        Segment length. If None, the model will accept every time window input\n",
    "        length.\n",
    "    eeg_input_dimension : int\n",
    "        number of channels of the EEG\n",
    "    env_input_dimension : int\n",
    "        dimemsion of the stimulus representation.\n",
    "        if stimulus == envelope, env_input_dimension =1\n",
    "        if stimulus == mel, env_input_dimension =28\n",
    "    layers : int\n",
    "        Depth of the network/Number of layers\n",
    "    kernel_size : int\n",
    "        Size of the kernel for the dilation convolutions\n",
    "    spatial_filters : int\n",
    "        Number of parallel filters to use in the spatial layer\n",
    "    dilation_filters : int\n",
    "        Number of parallel filters to use in the dilation layers\n",
    "    activation : str or list or tuple\n",
    "        Name of the non-linearity to apply after the dilation layers\n",
    "        or list/tuple of different non-linearities\n",
    "    compile : bool\n",
    "        If model should be compiled\n",
    "    inputs : tuple\n",
    "        Alternative inputs\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf.Model\n",
    "        The dilation model\n",
    "\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Accou, B., Jalilpour Monesi, M., Montoya, J., Van hamme, H. & Francart, T.\n",
    "    Modeling the relationship between acoustic stimulus and EEG with a dilated\n",
    "    convolutional neural network. In 2020 28th European Signal Processing\n",
    "    Conference (EUSIPCO), 1175â€“1179, DOI: 10.23919/Eusipco47968.2020.9287417\n",
    "    (2021). ISSN: 2076-1465.\n",
    "\n",
    "    Accou, B., Monesi, M. J., hamme, H. V. & Francart, T.\n",
    "    Predicting speech intelligibility from EEG in a non-linear classification\n",
    "    paradigm. J. Neural Eng. 18, 066008, DOI: 10.1088/1741-2552/ac33e9 (2021).\n",
    "    Publisher: IOP Publishing\n",
    "    \"\"\"\n",
    "\n",
    "    eeg = tf.keras.layers.Input(shape=[time_window, eeg_input_dimension])\n",
    "    stimuli_input = [tf.keras.layers.Input(shape=[time_window, env_input_dimension]) for _ in range(num_mismatched_segments+1)]\n",
    "\n",
    "    all_inputs = [eeg]\n",
    "    all_inputs.extend(stimuli_input)\n",
    "\n",
    "\n",
    "    stimuli_proj = [x for x in stimuli_input]\n",
    "\n",
    "    # Activations to apply\n",
    "    if isinstance(activation, str):\n",
    "        activations = [activation] * layers\n",
    "    else:\n",
    "        activations = activation\n",
    "\n",
    "\n",
    "    # Spatial convolution\n",
    "    eeg_proj_1 = tf.keras.layers.Conv1D(spatial_filters, kernel_size=1)(eeg)\n",
    "\n",
    "    # Construct dilation layers\n",
    "    for layer_index in range(layers):\n",
    "        # dilation on EEG\n",
    "        eeg_proj_1 = tf.keras.layers.Conv1D(\n",
    "            dilation_filters,\n",
    "            kernel_size=kernel_size,\n",
    "            dilation_rate=kernel_size ** layer_index,\n",
    "            strides=1,\n",
    "            activation=activations[layer_index],\n",
    "        )(eeg_proj_1)\n",
    "\n",
    "        # Dilation on envelope data, share weights\n",
    "        env_proj_layer = tf.keras.layers.Conv1D(\n",
    "            dilation_filters,\n",
    "            kernel_size=kernel_size,\n",
    "            dilation_rate=kernel_size ** layer_index,\n",
    "            strides=1,\n",
    "            activation=activations[layer_index],\n",
    "        )\n",
    "\n",
    "        stimuli_proj = [env_proj_layer(stimulus_proj) for stimulus_proj in stimuli_proj]\n",
    "\n",
    "\n",
    "    # Comparison\n",
    "    cos = [tf.keras.layers.Dot(1, normalize=True)([eeg_proj_1, stimulus_proj]) for stimulus_proj in stimuli_proj]\n",
    "\n",
    "    linear_proj_sim = tf.keras.layers.Dense(1, activation=\"linear\")\n",
    "\n",
    "    # Linear projection of similarity matrices\n",
    "    cos_proj = [linear_proj_sim(tf.keras.layers.Flatten()(cos_i)) for cos_i in cos]\n",
    "\n",
    "\n",
    "    # Classification\n",
    "    out = tf.keras.activations.softmax((tf.keras.layers.Concatenate()(cos_proj)))\n",
    "\n",
    "\n",
    "    model = tf.keras.Model(inputs=all_inputs, outputs=[out])\n",
    "\n",
    "    if compile:\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(),\n",
    "            metrics=[\"accuracy\"],\n",
    "            loss=[\"categorical_crossentropy\"],\n",
    "        )\n",
    "        print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T17:44:40.950299300Z",
     "start_time": "2023-11-21T17:44:40.939345400Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Code for the dataset_generator for both tasks.\"\"\"\n",
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def batch_equalizer_fn(*args):\n",
    "    \"\"\"Batch equalizer.\n",
    "    Prepares the inputs for a model to be trained in\n",
    "    match-mismatch task. It makes sure that match_env\n",
    "    and mismatch_env are equally presented as a first\n",
    "    envelope in match-mismatch task.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    args : Sequence[tf.Tensor]\n",
    "        List of tensors representing feature data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[Tuple[tf.Tensor], tf.Tensor]\n",
    "        Tuple of the EEG/speech features serving as the input to the model and\n",
    "        the labels for the match/mismatch task\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function will also double the batch size. E.g. if the batch size of\n",
    "    the elements in each of the args was 32, the output features will have\n",
    "    a batch size of 64.\n",
    "    \"\"\"\n",
    "    eeg = args[0]\n",
    "    num_stimuli = len(args) - 1\n",
    "    # repeat eeg num_stimuli times\n",
    "    new_eeg = tf.concat([eeg] * num_stimuli, axis=0)\n",
    "    all_features = [new_eeg]\n",
    "\n",
    "    # create args\n",
    "    args_to_zip = [args[i::num_stimuli] for i in range(1,num_stimuli+1)]\n",
    "    for stimuli_features in zip(*args_to_zip):\n",
    "\n",
    "        for i in range(num_stimuli):\n",
    "            stimulus_rolled = tf.roll(stimuli_features, shift=i, axis=0)\n",
    "            # reshape stimulus_rolled to merge the first two dimensions\n",
    "            stimulus_rolled = tf.reshape(stimulus_rolled, [tf.shape(stimulus_rolled)[0] * tf.shape(stimulus_rolled)[1], stimuli_features[0].shape[-2], stimuli_features[0].shape[-1]])\n",
    "\n",
    "            all_features.append(stimulus_rolled)\n",
    "    labels = tf.concat(\n",
    "        [\n",
    "            tf.tile(tf.constant([[1 if ii == i else 0 for ii in range(num_stimuli)]]), [tf.shape(eeg)[0], 1]) for i in range(num_stimuli)\n",
    "        ], axis=0\n",
    "    )\n",
    "\n",
    "    return tuple(all_features), labels\n",
    "\n",
    "def shuffle_fn(args, number_mismatch):\n",
    "    # repeat the last argument number_ mismatch times\n",
    "    args = list(args)\n",
    "    for _  in range(number_mismatch):\n",
    "        args.append(tf.random.shuffle(args[-1]))\n",
    "    return tuple(args)\n",
    "\n",
    "\n",
    "\n",
    "def create_tf_dataset(\n",
    "    data_generator,\n",
    "    window_length,\n",
    "    batch_equalizer_fn=None,\n",
    "    hop_length=64,\n",
    "    batch_size=64,\n",
    "    data_types=(tf.float32, tf.float32),\n",
    "    feature_dims=(64, 1),\n",
    "    number_mismatch = None # None for regression, 2 or 4 for match-mismatch\n",
    "):\n",
    "    \"\"\"Creates a tf.data.Dataset.\n",
    "\n",
    "    This will be used to create a dataset generator that will\n",
    "    pass windowed data to a model in both tasks.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    data_generator: DataGenerator\n",
    "        A data generator.\n",
    "    window_length: int\n",
    "        Length of the decision window in samples.\n",
    "    batch_equalizer_fn: Callable\n",
    "        Function that will be applied on the data after batching (using\n",
    "        the `map` method from tf.data.Dataset). In the match/mismatch task,\n",
    "        this function creates the imposter segments and labels.\n",
    "    hop_length: int\n",
    "        Hop length between two consecutive decision windows.\n",
    "    batch_size: Optional[int]\n",
    "        If not None, specifies the batch size. In the match/mismatch task,\n",
    "        this amount will be doubled by the default_batch_equalizer_fn\n",
    "    data_types: Union[Sequence[tf.dtype], tf.dtype]\n",
    "        The data types that the individual features of data_generator should\n",
    "        be cast to. If you only specify a single datatype, it will be chosen\n",
    "        for all EEG/speech features.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf.data.Dataset\n",
    "        A Dataset object that generates data to train/evaluate models\n",
    "        efficiently\n",
    "    \"\"\"\n",
    "    # create tf dataset from generator\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        data_generator,\n",
    "        output_signature=tuple(\n",
    "            tf.TensorSpec(shape=(None, x), dtype=data_types[index])\n",
    "            for index, x in enumerate(feature_dims)\n",
    "        ),\n",
    "    )\n",
    "    # window dataset\n",
    "    dataset = dataset.map(\n",
    "        lambda *args: [\n",
    "            tf.signal.frame(arg, window_length, hop_length, axis=0)\n",
    "            for arg in args\n",
    "        ],\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    if number_mismatch is not None:\n",
    "        # map second argument to shifted version\n",
    "\n",
    "\n",
    "        dataset = dataset.map( lambda *args : shuffle_fn(args, number_mismatch),\n",
    "\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        )\n",
    "    # batch data\n",
    "    dataset = dataset.interleave(\n",
    "        lambda *args: tf.data.Dataset.from_tensor_slices(args),\n",
    "        cycle_length=8,\n",
    "        block_length=1,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    )\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    if batch_equalizer_fn is not None:\n",
    "        # Create the labels and make sure classes are balanced\n",
    "        dataset = dataset.map(batch_equalizer_fn,\n",
    "                              num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def group_recordings(files):\n",
    "    \"\"\"Group recordings and corresponding stimuli.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    files : Sequence[Union[str, pathlib.Path]]\n",
    "        List of filepaths to preprocessed and split EEG and speech features\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Files grouped by the self.group_key_fn and subsequently sorted\n",
    "        by the self.feature_sort_fn.\n",
    "    \"\"\"\n",
    "    new_files = []\n",
    "    grouped = itertools.groupby(sorted(files), lambda x: \"_-_\".join(os.path.basename(x).split(\"_-_\")[:3]))\n",
    "    for recording_name, feature_paths in grouped:\n",
    "        new_files += [sorted(feature_paths, key=lambda x: \"0\" if x == \"eeg\" else x)]\n",
    "    return new_files\n",
    "\n",
    "\n",
    "\n",
    "class DataGenerator:\n",
    "    \"\"\"Generate data for the Match/Mismatch task.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        files,\n",
    "        window_length,\n",
    "    ):\n",
    "        \"\"\"Initialize the DataGenerator.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        files: Sequence[Union[str, pathlib.Path]]\n",
    "            Files to load.\n",
    "        window_length: int\n",
    "            Length of the decision window.\n",
    "        spacing: int\n",
    "            Spacing between matched and mismatched samples\n",
    "        \"\"\"\n",
    "        self.window_length = window_length\n",
    "        self.files = self.group_recordings(files)\n",
    "\n",
    "\n",
    "    def group_recordings(self, files):\n",
    "        \"\"\"Group recordings and corresponding stimuli.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        files : Sequence[Union[str, pathlib.Path]]\n",
    "            List of filepaths to preprocessed and split EEG and speech features\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            Files grouped by the self.group_key_fn and subsequently sorted\n",
    "            by the self.feature_sort_fn.\n",
    "        \"\"\"\n",
    "        new_files = []\n",
    "        grouped = itertools.groupby(sorted(files), lambda x: \"_-_\".join(os.path.basename(x).split(\"_-_\")[:3]))\n",
    "        for recording_name, feature_paths in grouped:\n",
    "            new_files += [sorted(feature_paths, key=lambda x: \"0\" if x == \"eeg\" else x)]\n",
    "        return new_files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, recording_index):\n",
    "        \"\"\"Get data for a certain recording.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        recording_index: int\n",
    "            Index of the recording in this dataset\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Union[Tuple[tf.Tensor,...], Tuple[np.ndarray,...]]\n",
    "            The features corresponding to the recording_index recording\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        for feature in self.files[recording_index]:\n",
    "            f = np.load(feature).astype(np.float32)\n",
    "            if f.ndim == 1:\n",
    "                f = f[:,None]\n",
    "\n",
    "            data += [f]\n",
    "        data = self.prepare_data(data)\n",
    "        return tuple(tf.constant(x) for x in data)\n",
    "\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"Load data for the next recording.\n",
    "\n",
    "        Yields\n",
    "        -------\n",
    "        Union[Tuple[tf.Tensor,...], Tuple[np.ndarray,...]]\n",
    "            The features corresponding to the recording_index recording\n",
    "        \"\"\"\n",
    "        for idx in range(self.__len__()):\n",
    "            yield self.__getitem__(idx)\n",
    "\n",
    "            if idx == self.__len__() - 1:\n",
    "                self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Change state at the end of an epoch.\"\"\"\n",
    "        np.random.shuffle(self.files)\n",
    "\n",
    "    def prepare_data(self, data):\n",
    "        # make sure data has dimensionality of (n_samples, n_features)\n",
    "\n",
    "\n",
    "        return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T17:44:42.038627Z",
     "start_time": "2023-11-21T17:44:41.943794Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydev_jupyter_utils'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m     sys\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39minsert(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mD:\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mProgram Files\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mJetBrains\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mPyCharm 2023.2.2\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mplugins\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpython\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mhelpers\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpydev\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      6\u001B[0m     sys\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39minsert(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mD:\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mProgram Files\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mJetBrains\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mPyCharm 2023.2.2\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mplugins\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpython\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mhelpers-pro\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mjupyter_debug\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpydev_jupyter_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m remove_imported_pydev_package\n\u001B[1;32m      8\u001B[0m remove_imported_pydev_package()\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpydev_jupyter_utils\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'pydev_jupyter_utils'"
     ]
    }
   ],
   "source": [
    "\"\"\"Example experiment for the 2 mismatched segments dilation model.\"\"\"\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import os, sys\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "# add base path to sys\n",
    "#sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))\n",
    "#from util.dataset_generator import DataGenerator, batch_equalizer_fn, create_tf_dataset\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_dict):\n",
    "    \"\"\"Evaluate a model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: tf.keras.Model\n",
    "        Model to evaluate.\n",
    "    test_dict: dict\n",
    "        Mapping between a subject and a tf.data.Dataset containing the test\n",
    "        set for the subject.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Mapping between a subject and the loss/evaluation score on the test set\n",
    "    \"\"\"\n",
    "    evaluation = {}\n",
    "    for subject, ds_test in test_dict.items():\n",
    "        logging.info(f\"Scores for subject {subject}:\")\n",
    "        results = model.evaluate(ds_test, verbose=2)\n",
    "        metrics = model.metrics_names\n",
    "        evaluation[subject] = dict(zip(metrics, results))\n",
    "    return evaluation\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    # Length of the decision window\n",
    "    window_length_s = 5\n",
    "    fs = 64\n",
    "\n",
    "    window_length = window_length_s * fs  # 5 seconds\n",
    "    # Hop length between two consecutive decision windows\n",
    "    hop_length = 64\n",
    "\n",
    "    epochs = 100\n",
    "    patience = 5\n",
    "    batch_size = 64\n",
    "    only_evaluate = False\n",
    "    number_mismatch = 4 # or 4\n",
    "\n",
    "\n",
    "\n",
    "    training_log_filename = \"training_log_{}_{}.csv\".format(number_mismatch, window_length_s)\n",
    "\n",
    "\n",
    "\n",
    "    # Get the path to the config gile\n",
    "    #experiments_folder = os.path.dirname(__file__)\n",
    "    #task_folder = os.path.dirname(experiments_folder)\n",
    "    #util_folder = os.path.join(os.path.dirname(task_folder), \"util\")\n",
    "    #config_path = os.path.join(util_folder, 'config.json')\n",
    "\n",
    "    # Load the config\n",
    "    #with open(config_path) as fp:\n",
    "    #    config = json.load(fp)\n",
    "\n",
    "    # Provide the path of the dataset\n",
    "    # which is split already to train, val, test\n",
    "    #data_folder = os.path.join(config[\"dataset_folder\"], config['derivatives_folder'], config[\"split_folder\"])\n",
    "    data_folder = \"split_data\"\n",
    "    experiments_folder = \"experiment3\"\n",
    "    \n",
    "\n",
    "    # stimulus feature which will be used for training the model. Can be either 'envelope' ( dimension 1) or 'mel' (dimension 28)\n",
    "    stimulus_features = [\"envelope\"]\n",
    "    stimulus_dimension = 1\n",
    "\n",
    "    # uncomment if you want to train with the mel spectrogram stimulus representation\n",
    "    # stimulus_features = [\"mel\"]\n",
    "    # stimulus_dimension = 10\n",
    "\n",
    "    features = [\"eeg\"] + stimulus_features\n",
    "\n",
    "    # Create a directory to store (intermediate) results\n",
    "    results_folder = os.path.join(experiments_folder, \"results_dilated_convolutional_model_{}_MM_{}_s_{}\".format(number_mismatch, window_length_s, stimulus_features[0]))\n",
    "    os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "    # create dilation model\n",
    "    model = dilation_model(time_window=window_length, eeg_input_dimension=64, env_input_dimension=stimulus_dimension, num_mismatched_segments = number_mismatch)\n",
    "\n",
    "    model_path = os.path.join(results_folder, \"model_{}_MM_{}_s_{}.h5\".format(number_mismatch, window_length_s, stimulus_features[0]))\n",
    "\n",
    "    if only_evaluate:\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    else:\n",
    "\n",
    "        train_files = [x for x in glob.glob(os.path.join(data_folder, \"train_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "        # Create list of numpy array files\n",
    "        train_generator = DataGenerator(train_files, window_length)\n",
    "        import pdb\n",
    "        dataset_train = create_tf_dataset(train_generator, window_length, batch_equalizer_fn,\n",
    "                                          hop_length, batch_size,\n",
    "                                          number_mismatch=number_mismatch,\n",
    "                                          data_types=(tf.float32, tf.float32),\n",
    "                                          feature_dims=(64, stimulus_dimension))\n",
    "\n",
    "        # Create the generator for the validation set\n",
    "        val_files = [x for x in glob.glob(os.path.join(data_folder, \"val_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "        val_generator = DataGenerator(val_files, window_length)\n",
    "        dataset_val = create_tf_dataset(val_generator,  window_length, batch_equalizer_fn,\n",
    "                                          hop_length, batch_size,\n",
    "                                          number_mismatch=number_mismatch,\n",
    "                                          data_types=(tf.float32, tf.float32),\n",
    "                                          feature_dims=(64, stimulus_dimension))\n",
    "\n",
    "\n",
    "        # Train the model\n",
    "        with tf.device('/GPU:0'):\n",
    "            model.fit(\n",
    "                dataset_train,\n",
    "                epochs=epochs,\n",
    "                validation_data=dataset_val,\n",
    "                callbacks=[\n",
    "                    tf.keras.callbacks.ModelCheckpoint(model_path, save_best_only=True),\n",
    "                    tf.keras.callbacks.CSVLogger(os.path.join(results_folder, training_log_filename)),\n",
    "                    tf.keras.callbacks.EarlyStopping(patience=patience, restore_best_weights=True),\n",
    "                ],\n",
    "            )\n",
    "\n",
    "    test_window_lengths = [3,5]\n",
    "    number_mismatch_test = [2,3,4, 8]\n",
    "    for number_mismatch in number_mismatch_test:\n",
    "        for window_length_s in test_window_lengths:\n",
    "            window_length = window_length_s * fs\n",
    "            results_filename = 'eval_{}_{}_s.json'.format(number_mismatch, window_length_s)\n",
    "\n",
    "            model = dilation_model(time_window=window_length, eeg_input_dimension=64,\n",
    "                                   env_input_dimension=stimulus_dimension, num_mismatched_segments=number_mismatch)\n",
    "\n",
    "            model.load_weights(model_path)\n",
    "            # Evaluate the model on test set\n",
    "            # Create a dataset generator for each test subject\n",
    "            test_files = [x for x in glob.glob(os.path.join(data_folder, \"test_-_*\")) if\n",
    "                          os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "            # Get all different subjects from the test set\n",
    "            subjects = list(set([os.path.basename(x).split(\"_-_\")[1] for x in test_files]))\n",
    "            datasets_test = {}\n",
    "            # Create a generator for each subject\n",
    "            for sub in subjects:\n",
    "                files_test_sub = [f for f in test_files if sub in os.path.basename(f)]\n",
    "                test_generator = DataGenerator(files_test_sub, window_length)\n",
    "                datasets_test[sub] = create_tf_dataset(test_generator, window_length, batch_equalizer_fn,\n",
    "                                                       hop_length, batch_size=1,\n",
    "                                                       number_mismatch=number_mismatch,\n",
    "                                                       data_types=(tf.float32, tf.float32),\n",
    "                                                       feature_dims=(64, stimulus_dimension))\n",
    "\n",
    "            evaluation = evaluate_model(model, datasets_test)\n",
    "\n",
    "            # We can save our results in a json encoded file\n",
    "            results_path = os.path.join(results_folder, results_filename)\n",
    "            with open(results_path, \"w\") as fp:\n",
    "                json.dump(evaluation, fp)\n",
    "            logging.info(f\"Results saved at {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T17:43:55.773072200Z",
     "start_time": "2023-11-21T17:43:55.768070800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n",
      "Is GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Is GPU available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T17:42:36.366196900Z",
     "start_time": "2023-11-21T17:42:35.969347500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 21 12:42:35 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA L40                     On  | 00000000:24:00.0 Off |                    0 |\r\n",
      "| N/A   45C    P0              80W / 300W |  45164MiB / 46068MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A     11309      C   python3.10                                 1274MiB |\r\n",
      "|    0   N/A  N/A    205201      C   ...ss6928/.conda/envs/myenv/bin/python    43872MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T17:42:47.222606100Z",
     "start_time": "2023-11-21T17:42:47.031531100Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-.conda-myenv-py",
   "language": "python",
   "display_name": "Python [conda env:.conda-myenv]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
